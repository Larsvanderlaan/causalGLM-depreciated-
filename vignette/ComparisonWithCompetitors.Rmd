---
title: "SimulationComparisonWithCompetitors"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Disclaimer: These simulations are not necessarily representative of the performance of these methods in the real-world. The simulation models are all randomly generated main-term parametric models and there are little-to-no positivity issues. Because of this, glm/glmnet will do better than other machine-learning algorithms in the below simulations. To make the comparison more fair, look at the arguments to the function sim.causalGLM. 


# Simulation Comparison with estimating-equation competitors  

The sim.R function contains customizable functions that randomly generate test data for both the CATE, RR, and OR functions. The functions sim.causalGLM and sim.causalGLMwithLasso internally call these functions and run nsims number of simulations and report the proportion of estimated 95% confidence intervals that contain the true coefficient values (as determined from the simulation). The confidence interval coverage for the competitor, estimating equation-based estimators, is also reported. Both methods are fit on the same simulation data with the same nuisance estimators and same variance estimator. Therefore, the randomness is only in the difference between the two methods. We will employ these methods to compare the TMLE method implemented in this package, causalGLM, with competitors. 

We will focus on small n with a 4-dimensional covariate model for the estimand. In these settings, differences are especially pronounced. The simulation data distributions are linear main-term parametric models, so that glm and glmnet are correctly specified. This may be unrealistic in some settings but it is an important benchmark. We would like these methods to do just as well as parametric glm in coverage when the assumptions are true.

Note sometimes due to montecarlo randomness one method may by chance perform better than another. For most reliable and fair results, set "nsims" as high as possible, e.g. nsims = 1000 or 2500.

Note the competitor is asyptotically equivalent to causalGLM. There for n large enough (e.g. n=1000), any differences should become smaller.  


```{r}
library(causalGLM)
seed <- 12345
 
nsims <- 100
 
```
## CATE
The estimating equation for CATE is fairly simple (it is linear). Thus, estimating equation estimators should perform better for the CATE relative to non-linear estimating equation estimators (like for RR).
### n = 50, p=5
```{r, echo = F, include = F}
set.seed(seed) 
n <- 50
p <- 5
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 + W2 + W3 + W4, n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "CATE", compare_with_competitor = T)

 

```
```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

### You should see causalGLM do much better than the estimating equation estimator. The >0.95 coverage is likely due to glmnet being a correct parametric model which leads to superefficiency.

```




### n = 100, p=5
```{r, echo = F, include = F}
set.seed(seed) 
n <- 100
p <- 5
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 + W2 + W3 + W4, n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "CATE", compare_with_competitor = T)

 

```
```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

### You should see causalGLM do better than the estimating equation estimator. The >0.95 coverage is likely due to glmnet being a correct parametric model which leads to superefficiency.

```



### n = 200, p=5
```{r, echo = F, include = F}
set.seed(seed) 
n <- 200
p <- 5
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 + W2 + W3 + W4, n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "CATE", compare_with_competitor = T)

 

```
```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

### You should see both methods do fairly well. But, causalGLM does a bit better than the estimating equation estimator.

```







## RR
The estimating equation for RR is highly non-linear. This should lead to worse performance for the estimating equation in certain settings.
### n = 50, p=5
```{r, echo = F, include = F}
set.seed(seed) 
n <- 50
p <- 5
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 + W2 + W3 + W4, n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "RR", compare_with_competitor = T)

 

```
```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

### You should see causalGLM do much better than the estimating equation estimator. The >0.95 coverage is likely due to glmnet being a correct parametric model which leads to superefficiency.

```




### n = 100, p=5
```{r, echo = F, include = F}
set.seed(seed) 
n <- 100
p <- 5
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 + W2 + W3 + W4, n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "RR", compare_with_competitor = T)

 

```
```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

### You should see causalGLM do better than the estimating equation estimator. The >0.95 coverage is likely due to glmnet being a correct parametric model which leads to superefficiency.

```



### n = 200,  p=5
```{r, echo = F, include = F}
set.seed(seed) 
n <- 200
p <- 5
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 + W2 + W3 + W4, n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "RR", compare_with_competitor = T)

 

```
```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

### You should see causalGLM do better than the competing estimating equation method.

```






## OR
  
### n = 50, p=5
```{r, echo = F, include = F}
set.seed(seed)
n <-   50
p <- 4
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
  out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 +W2 + W3 + W4   , n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "OR", compare_with_competitor = T)

# Both do great here!
 
x <-  sim.OR(formula_estimand = ~1 + W1 + W2 + W3 + W4, n=n, p=p)
x$data[, -c(1:5)]

```

```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

# Both methods do great here!
```




### n = 100, p=5
```{r, echo = F, include = F}
set.seed(seed)
n <- 100
p <- 4
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 + W2 + W3 + W4, n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "OR", compare_with_competitor = T)

 

```

```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

### Similar performance again
```



### n = 200,  p=5
```{r, echo = F, include = F}
set.seed(seed)
n <- 200
p <- 4
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 out <-  sim.causalGLM(cross_fit = F, formula = ~1 + W1 + W2 + W3 + W4, n=n, p = p, learning_method = "glmnet", nsims = nsims, estimand= "OR", compare_with_competitor = T)

 

```

```{r}


# The report function summarizes the coverage
# The first row of values is the coverage probability for each coeficient obtained by causalGLM. These values should be 0.95 or larger ideally. Less than 0.95 is undercoverage and is considered bad.
 out$report()

### You should see causalGLM do better than the competing estimating equation method.

```



# High dimensional comparison with causalGLMwithLASSO

```{r, echo = F, include = F}
set.seed(seed) 
n <- 50
p <- 200
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 
bigformula <- ~ 1 + W12 + + W2 + W3 + W112 + W123 + W154 + W45 + W34 + W121  + W63 + W164 + W162 + W63 + W119 +  W22 + W3 + W4 + W50 + W86 + W25 + W118 + W99 + W10 + W110 + W112 + W113 + W14 + W190+ W16 + W150 + W133 + W122 + W156

smallformula <- ~ 1 + W12 + W50  + W99 + W14 

out <-   sim.causalGLMwithLasso(formula = smallformula, n = n, p = p, formula_A = bigformula, formula_Y0W = bigformula, compare_with_competitor = T, nsims = nsims, cross_fit = TRUE, estimand= "CATE")


```

```{r}

 out$report()

### You should see causalGLM do substantially better than the competing estimating equation method.

```

```{r, echo = F, include = F}
set.seed(seed) 
n <- 100
p <- 200
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 
bigformula <- ~ 1 + W12 + + W2 + W3 + W112 + W123 + W154 + W45 + W34 + W121  + W63 + W164 + W162 + W63 + W119 +  W22 + W3 + W4 + W50 + W86 + W25 + W118 + W99 + W10 + W110 + W112 + W113 + W14 + W190+ W16 + W150 + W133 + W122 + W156

smallformula <- ~ 1 + W12 + W50  + W99 + W14 

out <-   sim.causalGLMwithLasso(formula = smallformula, n = n, p = p, formula_A = bigformula, formula_Y0W = bigformula, compare_with_competitor = T, nsims = nsims, cross_fit = TRUE, estimand= "CATE")


```


```{r}

 out$report()

### You should see causalGLM do substantially better than the competing estimating equation method.

```




```{r, echo = F, include = F}
set.seed(seed) 
n <- 250
p <- 200
#n=50 is sample size
#p=4 is number of covariates in W
### This will print updates of coverage per iteration to your consol. It should run in a minute or so.
 
bigformula <- ~ 1 + W12 + + W2 + W3 + W112 + W123 + W154 + W45 + W34 + W121  + W63 + W164 + W162 + W63 + W119 +  W22 + W3 + W4 + W50 + W86 + W25 + W118 + W99 + W10 + W110 + W112 + W113 + W14 + W190+ W16 + W150 + W133 + W122 + W156

smallformula <- ~ 1 + W12 + W50  + W99 + W14 
# Cross-fitting is turned off for speed
out <-   sim.causalGLMwithLasso(formula = smallformula, n = n, p = p, formula_A = bigformula, formula_Y0W = bigformula, compare_with_competitor = T, nsims = nsims, cross_fit = FALSE, estimand= "CATE")


```


```{r}

 out$report()

### The two methods perform similar, but it looks like causalGLM has a slight edge.

```