% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/causalGLM.R
\name{causalGLM}
\alias{causalGLM}
\title{causalGLM
A default and more user-friendly front-end of the implemented methods.
Supports conditional average treatment effect (CATE), conditional odds ratio (OR), and conditional relative risk (RR) estimation
Highly Adaptive Lasso (HAL, R package: tlverse/hal9001), a flexible and adaptive spline regression estimator, is used as default learner (piece-wise linear).}
\usage{
causalGLM(
  formula,
  W,
  A,
  Y,
  estimand = c("CATE", "OR", "RR"),
  learning_method = c("autoHAL", "glm", "glmnet", "gam", "mars", "ranger", "xgboost"),
  pool_A_when_training = TRUE,
  cross_fit = ifelse(ncol(W) >= 12, T, F),
  sl3_Learner_A = NULL,
  sl3_Learner_Y = NULL,
  glm_formula_A = NULL,
  glm_formula_Y = NULL,
  weights = NULL,
  data_list = NULL,
  parallel = F,
  ncores = NULL,
  smoothness_order_Y0W = 1,
  max_degree_Y0W = ifelse(nrow(W) >= 200, 2, 1),
  num_knots_Y0W = c(ifelse(nrow(W) >= 500 && ncol(W) <= 20, 20, 10), 5, 1),
  constant_variance_CATE = FALSE,
  ...
)
}
\arguments{
\item{formula}{A R formula object specifying the parametric form of CATE, OR, or RR (depending on method).}

\item{W}{A named matrix or data.frame of baseline covariates to condition on.}

\item{A}{A binary treatment assignment vector}

\item{Y}{n outcome variable (continuous, nonnegative or binary depending on method)}

\item{estimand}{Estimand/parameter to estimate. Choices are:
CATE: Estimate conditional average treatment effect with \code{spCATE} assuming it satisfies parametric model \code{formula}.
OR: Estimate conditional odds ratio with \code{spOR} assuming it satisfies parametric model \code{formula}.
OR: Estimate conditional relative risk with \code{spRR} assuming it satisfies parametric model \code{formula}.}

\item{learning_method}{Machine-learning method to use. This is overrided if argument \code{sl3_Learner} is provided. Options are:
"autoHAL": Adaptive robust automatic machine-learning using the Highly Adaptive Lasso \code{hal9001} Good for most sample sizes when propertly tuned. See arguments \code{max_degree_Y0W} and \code{num_knots_Y0W}.
"glm": Fit nuisances with parametric model. Best for smaller sample sizes (e.g. n =30-100). See arguments \code{glm_formula_A}, \code{glm_formula_Y} and \code{glm_formula_Y0}.
"glmnet": Learn using lasso with glmnet. Best for smaller sample sizes (e.g. n =30-100)
"gam": Learn using generalized additive models with mgcv. Good for small-to-medium-small sample sizes.
"mars": Multivariate adaptive regression splines with \code{earth}. Good for small-to-medium-small sample sizes.
"ranger": Robust random-forests with the package \code{Ranger} Good for medium-to-large sample sizes.
"xgboost": Learn using a default cross-validation tuned xgboost library with max_depths 3 to 7. Good for medium-to-large sample sizes.
We recommend performing simulations checking 95% CI coverage when choosing learners (especially in smaller sample sizes).}

\item{pool_A_when_training}{Default: TRUE. This argument is ignored if \code{learning_method} = `autoHAL`, `glm`, `gam`, or `glmnet` and \code{sl3_Learner_Y0W} is NULL. 
Otherwise this is a boolean for whether to estimate the conditional mean/regression of Y by combining observations with A=0,A=1 ...
Or to estimate E[Y|A=1,W] and E[Y|A=0,W] with separate regressions (this is nonparametric in the interaction with A).
When \code{pool_A_when_training} is TRUE, the design matrix passed to the regression algorithm/learner is cbind(W,A*V) where V is the design matrix specified by the argument \code{formula}.
Therefore, it may not be necessary to use learners that model (treatment) interactions when this argument is TRUE.
For \code{learning_method} = glm, gam,  mars, and glmnet this argument is set to TRUE automatically.
In high dimensions, pool_A_when_training = FALSE may be preferred to prevent dilution of the treatment interactions in the fitting.}

\item{cross_fit}{Whether to cross-fit the initial estimator. This is always set to FALSE if argument \code{sl3_Learner} is provided.
learning_method = AutoML (default) does use cross-fitting for computational reasons and due to it being unnecessary for HAL.
learning_method = `xgboost` and `ranger` are always cross-fitted regardless of the value of \code{cross_fit}
All other learning_methods are only cross-fitted if `cross_fit=TRUE`. 
Note, it is not necessary to cross-fit glm, glmnet, gam or mars as long as the dimension of W is not too high.
In smaller samples and lower dimensions, it may fact hurt to cross-fit.}

\item{sl3_Learner_A}{A \code{sl3} Learner object to use to estimate nuisance function P(A=1|W) with machine-learning.
Note, \code{cross_fit} is automatically set to FALSE if this argument is provided. 
If you wish to cross-fit the learner \code{sl3_Learner} then do: sl3_Learner <- Lrnr_cv$new(sl3_Learner).
Cross-fitting is recommended for all tree-based algorithms like random-forests and gradient-boosting.}

\item{sl3_Learner_Y}{A \code{sl3} Learner object to use to estimate nuisance functions [Y|A=1,W] and E[Y|A=0,W] (depending on method) with machine-learning.
Note, \code{cross_fit} is automatically set to FALSE if this argument is provided. 
Keep in mind the value of the argument \code{pool_A_when_training}. If FALSE  then E[Y|A=0,W] is estimated by itself. 
Therefore, it may not be needed to add interactions, since treatment interactions are automatic by stratification.
If TRUE, the design matrix passed to the pooled learner contains A*V where V is the design matrix obtained from \code{formula}.
For some learners, it may also be unnecessary to include interactions in this case.
#' If you wish to cross-fit the learner \code{sl3_Learner} then do: sl3_Learner <- Lrnr_cv$new(sl3_Learner).
Cross-fitting is recommended for all tree-based algorithms like random-forests and gradient-boosting.}

\item{glm_formula_A}{A glm formula for P(A=1|W). Only used if learning_method = "glm".}

\item{glm_formula_Y}{A glm formula for E[Y|A,W] or E[Y|A=0,W] depending on method. Only used if learning_method = "glm".}

\item{weights}{An optional vector of weights to use in procedure.}

\item{data_list}{A named list containing the arguments `W`, `A` and `Y`. For example, data_list = list(W = data[,c("W1", "W2")], A = data[,"A"], Y = data[,"Y"])}

\item{parallel}{Whether to parallize HAL whenever it is used in fitting.}

\item{ncores}{Number of cores to use in parallelization.}

\item{smoothness_order_Y0W}{Smoothness order for HAL estimator of E[Y|A=0,W] (see \code{hal9001/fit_hal})
smoothness_order_Y0W = 1 is piece-wise linear. smoothness_order_Y0W = 0 is piece-wise constant.}

\item{max_degree_Y0W}{Max interaction degree for HAL estimator of E[Y|A=0,W] (see \code{hal9001/fit_hal})}

\item{num_knots_Y0W}{Number of knots by interaction degree for HAL estimator of E[Y|A=0,W](see \code{hal9001/fit_hal}). Used to generate basis functions.
num_knots_Y0W = c(1) is equivalent to main term glmnet/LASSO. (Assuming max_degree_Y0W = 1)
num_knots_Y0W = c(1,1) is equivalent to glmnet/LASSO with both main-terms and all two-way interactions (e.g. Y~ W1 + W1 + W1*W2 + ...).  (Assuming max_degree_Y0W = 2)
num_knots_Y0W = c(10) is an additive piece-wise linear model with 10 knot points.  (Assuming max_degree_Y0W = 1)
num_knots_Y0W = c(10,5) is a bi-additive model with the same one-way basis functions as above, but also two-way interaction piece-wise linear basis functions generated by main-term one-way basis functions with 5 knots. (Assuming max_degree_Y0W = 2)
num_knots_Y0W = c(10,5,1) generates same basis functions as above and also the three-way interaction basis functions with only a single knot point at the origin (e.g. the triple interaction `W1*W2*W3`) (Assuming max_degree_Y0W = 3)}

\item{...}{Other arguments to pass to main routine (spCATE, spOR, spRR)}
}
\description{
causalGLM
A default and more user-friendly front-end of the implemented methods.
Supports conditional average treatment effect (CATE), conditional odds ratio (OR), and conditional relative risk (RR) estimation
Highly Adaptive Lasso (HAL, R package: tlverse/hal9001), a flexible and adaptive spline regression estimator, is used as default learner (piece-wise linear).
}
